{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzXNTKB3ulxAPw6Kkd6GgT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shin0729/Spatial-Lecture-on-NLP-implementation/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLWvUwU57P08",
        "outputId": "c7db4ab1-01f1-45d4-e646-4006d0a2ecd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SpEL'...\n",
            "remote: Enumerating objects: 421, done.\u001b[K\n",
            "remote: Counting objects: 100% (170/170), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 421 (delta 116), reused 109 (delta 75), pack-reused 251\u001b[K\n",
            "Receiving objects: 100% (421/421), 33.22 MiB | 13.95 MiB/s, done.\n",
            "Resolving deltas: 100% (221/221), done.\n",
            "/content/SpEL/SpEL/src/spel\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shavarani/SpEL.git\n",
        "%cd /content/SpEL/SpEL/src/spel\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qBWxu577gwo",
        "outputId": "50952d5d-19a5-4b38-c90c-9ae6ad623288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: numpy==1.25.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.25.1)\n",
            "Requirement already satisfied: transformers==4.26.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.26.1)\n",
            "Requirement already satisfied: torchtext==0.14.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.14.1)\n",
            "Requirement already satisfied: torchdata==0.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.5.1)\n",
            "Requirement already satisfied: mosestokenizer==1.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: wandb==0.15.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.15.7)\n",
            "Requirement already satisfied: st-annotated-text in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (0.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (0.13.3)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.14.1->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.1->-r requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.1->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from mosestokenizer==1.2.1->-r requirements.txt (line 6)) (0.6.2)\n",
            "Requirement already satisfied: openfile in /usr/local/lib/python3.10/dist-packages (from mosestokenizer==1.2.1->-r requirements.txt (line 6)) (0.0.7)\n",
            "Requirement already satisfied: uctools in /usr/local/lib/python3.10/dist-packages (from mosestokenizer==1.2.1->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: toolwrapper in /usr/local/lib/python3.10/dist-packages (from mosestokenizer==1.2.1->-r requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (3.1.43)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (2.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.7->-r requirements.txt (line 7)) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchtext==0.14.1->-r requirements.txt (line 4)) (4.11.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchtext==0.14.1->-r requirements.txt (line 4)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchtext==0.14.1->-r requirements.txt (line 4)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchtext==0.14.1->-r requirements.txt (line 4)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchtext==0.14.1->-r requirements.txt (line 4)) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchtext==0.14.1->-r requirements.txt (line 4)) (0.43.0)\n",
            "Requirement already satisfied: htbuilder in /usr/local/lib/python3.10/dist-packages (from st-annotated-text->-r requirements.txt (line 8)) (0.6.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.15.7->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.7->-r requirements.txt (line 7)) (4.0.11)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from htbuilder->st-annotated-text->-r requirements.txt (line 8)) (10.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.7->-r requirements.txt (line 7)) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/SpEL/src')\n",
        "!wget -O model.pt https://vault.sfu.ca/index.php/s/kBBlYVM4Tr59P0q/download\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9DlRCcX8WAz",
        "outputId": "ca689e2b-9188-4fa8-a61d-6ca25fa2907e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-22 11:56:24--  https://vault.sfu.ca/index.php/s/kBBlYVM4Tr59P0q/download\n",
            "Resolving vault.sfu.ca (vault.sfu.ca)... 142.58.225.42\n",
            "Connecting to vault.sfu.ca (vault.sfu.ca)|142.58.225.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1444752929 (1.3G) [application/octet-stream]\n",
            "Saving to: ‘model.pt’\n",
            "\n",
            "model.pt            100%[===================>]   1.34G   666KB/s    in 36m 18s \n",
            "\n",
            "2024-05-22 12:32:43 (648 KB/s) - ‘model.pt’ saved [1444752929/1444752929]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/SpEL/src/spel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipzVG_gTJAPQ",
        "outputId": "2a8673fd-9601-4257-e382-046b4938fb30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aida.py\t\t      data_loader.py\t  finetune_step_2.py  server.py\n",
            "base_model.cfg\t      decao_eval.py\t  finetune_step_3.py  span_annotation.py\n",
            "candidate_manager.py  evaluate_local.py   model.py\t      utils.py\n",
            "configuration.py      finetune_step_1.py  __pycache__\t      visualize.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from spel.model import SpELAnnotator\n",
        "from spel.configuration import device\n",
        "from spel.utils import get_subword_to_word_mapping\n",
        "from spel.span_annotation import WordAnnotation, PhraseAnnotation\n",
        "finetuned_after_step = 4\n",
        "sentence = \"Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) focused on the interaction between computers and human language. It involves the application of computational techniques to analyze and synthesize natural language and speech. Key tasks in NLP include language modeling, syntactic parsing, machine translation, sentiment analysis, and named entity recognition. Recent advancements in deep learning, particularly transformer-based models like BERT and GPT, have significantly improved the performance of NLP systems, enabling more accurate and sophisticated language understanding and generation.\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "# ############################################# LOAD SpEL #############################################################\n",
        "spel = SpELAnnotator()\n",
        "spel.init_model_from_scratch(device=device)\n",
        "if finetuned_after_step == 3:\n",
        "    spel.shrink_classification_head_to_aida(device)\n",
        "spel.load_checkpoint(None, device=device, load_from_torch_hub=True, finetuned_after_step=finetuned_after_step)\n",
        "# ############################################# RUN SpEL ##############################################################\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "token_offsets = list(zip(inputs.encodings[0].tokens,inputs.encodings[0].offsets))\n",
        "subword_annotations = spel.annotate_subword_ids(inputs.input_ids, k_for_top_k_to_keep=10, token_offsets=token_offsets)\n",
        "# #################################### CREATE WORD-LEVEL ANNOTATIONS ##################################################\n",
        "tokens_offsets = token_offsets[1:-1]\n",
        "subword_annotations = subword_annotations[1:]\n",
        "word_annotations = [WordAnnotation(subword_annotations[m[0]:m[1]], tokens_offsets[m[0]:m[1]])\n",
        "                    for m in get_subword_to_word_mapping(inputs.tokens(), sentence)]\n",
        "# ################################## CREATE PHRASE-LEVEL ANNOTATIONS ##################################################\n",
        "phrase_annotations = []\n",
        "for w in word_annotations:\n",
        "    if not w.annotations:\n",
        "        continue\n",
        "    if phrase_annotations and phrase_annotations[-1].resolved_annotation == w.resolved_annotation:\n",
        "        phrase_annotations[-1].add(w)\n",
        "    else:\n",
        "        phrase_annotations.append(PhraseAnnotation(w))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyfgRiKt8ZBb",
        "outputId": "1bb0fca5-6ace-4c16-bbd4-9a66ac581457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Loaded pretrained model checkpoint: spel-base-step-3-500K.pt\n",
            " * Loaded model with 511844697 number of parameters (124697433 parameters for the encoder and 387147264 parameters for the classification head)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word-Level Annotations\n",
        "print(\"Word-Level Annotations:\")\n",
        "for word_annotation in word_annotations:\n",
        "    print(f\"Word: {word_annotation.word_string}, Annotation: {word_annotation.resolved_annotation}\")\n",
        "\n",
        "# Phrase-Level Annotations\n",
        "print(\"\\nPhrase-Level Annotations:\")\n",
        "for phrase_annotation in phrase_annotations:\n",
        "    phrase_text = ' '.join([word.word_string for word in phrase_annotation.words])\n",
        "    print(f\"Phrase: {phrase_text}, Annotation: {phrase_annotation._resolved_annotation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ5s9eLZnGz6",
        "outputId": "24d58db4-6412-4536-c637-82273fdd3fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word-Level Annotations:\n",
            "Word: Natural, Annotation: 0\n",
            "Word: Language, Annotation: 0\n",
            "Word: Processing, Annotation: 0\n",
            "Word: (, Annotation: 0\n",
            "Word: NLP, Annotation: 0\n",
            "Word: ), Annotation: 0\n",
            "Word: is, Annotation: 0\n",
            "Word: a, Annotation: 0\n",
            "Word: subfield, Annotation: 0\n",
            "Word: of, Annotation: 0\n",
            "Word: artificial, Annotation: 21982\n",
            "Word: intelligence, Annotation: 21982\n",
            "Word: (, Annotation: 0\n",
            "Word: AI, Annotation: 0\n",
            "Word: ), Annotation: 0\n",
            "Word: focused, Annotation: 0\n",
            "Word: on, Annotation: 0\n",
            "Word: the, Annotation: 0\n",
            "Word: interaction, Annotation: 0\n",
            "Word: between, Annotation: 0\n",
            "Word: computers, Annotation: 12180\n",
            "Word: and, Annotation: 0\n",
            "Word: human, Annotation: 0\n",
            "Word: language, Annotation: 0\n",
            "Word: ., Annotation: 0\n",
            "Word: It, Annotation: 0\n",
            "Word: involves, Annotation: 0\n",
            "Word: the, Annotation: 0\n",
            "Word: application, Annotation: 0\n",
            "Word: of, Annotation: 0\n",
            "Word: computational, Annotation: 0\n",
            "Word: techniques, Annotation: 0\n",
            "Word: to, Annotation: 0\n",
            "Word: analyze, Annotation: 0\n",
            "Word: and, Annotation: 0\n",
            "Word: synthesize, Annotation: 0\n",
            "Word: natural, Annotation: 10065\n",
            "Word: language, Annotation: 10065\n",
            "Word: and, Annotation: 0\n",
            "Word: speech, Annotation: 0\n",
            "Word: ., Annotation: 0\n",
            "Word: Key, Annotation: 0\n",
            "Word: tasks, Annotation: 0\n",
            "Word: in, Annotation: 0\n",
            "Word: NLP, Annotation: 0\n",
            "Word: include, Annotation: 0\n",
            "Word: language, Annotation: 0\n",
            "Word: modeling, Annotation: 0\n",
            "Word: ,, Annotation: 0\n",
            "Word: syntactic, Annotation: 0\n",
            "Word: parsing, Annotation: 0\n",
            "Word: ,, Annotation: 0\n",
            "Word: machine, Annotation: 139262\n",
            "Word: translation, Annotation: 139262\n",
            "Word: ,, Annotation: 0\n",
            "Word: sentiment, Annotation: 174131\n",
            "Word: analysis, Annotation: 174131\n",
            "Word: ,, Annotation: 0\n",
            "Word: and, Annotation: 0\n",
            "Word: named, Annotation: 405582\n",
            "Word: entity, Annotation: 405582\n",
            "Word: recognition, Annotation: 0\n",
            "Word: ., Annotation: 0\n",
            "Word: Recent, Annotation: 0\n",
            "Word: advancements, Annotation: 0\n",
            "Word: in, Annotation: 0\n",
            "Word: deep, Annotation: 120874\n",
            "Word: learning, Annotation: 120874\n",
            "Word: ,, Annotation: 0\n",
            "Word: particularly, Annotation: 0\n",
            "Word: transformer-based, Annotation: 0\n",
            "Word: models, Annotation: 0\n",
            "Word: like, Annotation: 0\n",
            "Word: BERT, Annotation: 229520\n",
            "Word: and, Annotation: 0\n",
            "Word: GPT, Annotation: 81192\n",
            "Word: ,, Annotation: 0\n",
            "Word: have, Annotation: 0\n",
            "Word: significantly, Annotation: 0\n",
            "Word: improved, Annotation: 0\n",
            "Word: the, Annotation: 0\n",
            "Word: performance, Annotation: 0\n",
            "Word: of, Annotation: 0\n",
            "Word: NLP, Annotation: 0\n",
            "Word: systems, Annotation: 0\n",
            "Word: ,, Annotation: 0\n",
            "Word: enabling, Annotation: 0\n",
            "Word: more, Annotation: 0\n",
            "Word: accurate, Annotation: 0\n",
            "Word: and, Annotation: 0\n",
            "Word: sophisticated, Annotation: 0\n",
            "Word: language, Annotation: 0\n",
            "Word: understanding, Annotation: 0\n",
            "Word: and, Annotation: 0\n",
            "Word: generation, Annotation: 0\n",
            "Word: ., Annotation: 0\n",
            "\n",
            "Phrase-Level Annotations:\n",
            "Phrase: Natural Language Processing ( NLP ) is a subfield of, Annotation: 0\n",
            "Phrase: artificial intelligence, Annotation: 21982\n",
            "Phrase: ( AI ) focused on the interaction between, Annotation: 0\n",
            "Phrase: computers, Annotation: 12180\n",
            "Phrase: and human language . It involves the application of computational techniques to analyze and synthesize, Annotation: 0\n",
            "Phrase: natural language, Annotation: 10065\n",
            "Phrase: and speech . Key tasks in NLP include language modeling , syntactic parsing ,, Annotation: 0\n",
            "Phrase: machine translation, Annotation: 139262\n",
            "Phrase: ,, Annotation: 0\n",
            "Phrase: sentiment analysis, Annotation: 174131\n",
            "Phrase: , and, Annotation: 0\n",
            "Phrase: named entity, Annotation: 405582\n",
            "Phrase: recognition . Recent advancements in, Annotation: 0\n",
            "Phrase: deep learning, Annotation: 120874\n",
            "Phrase: , particularly transformer-based models like, Annotation: 0\n",
            "Phrase: BERT, Annotation: 229520\n",
            "Phrase: and, Annotation: 0\n",
            "Phrase: GPT, Annotation: 81192\n",
            "Phrase: , have significantly improved the performance of NLP systems , enabling more accurate and sophisticated language understanding and generation ., Annotation: 0\n"
          ]
        }
      ]
    }
  ]
}